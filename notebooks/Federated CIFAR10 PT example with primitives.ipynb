{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLEXible tutorial: CIFAR10 classification using Pytorch\n",
    "\n",
    "FLEXible is a library to federate models. We offer the tools to load and federate data or to load federated data, and the tools to create a federated environment. The user can define the model and the *communication primitives* to train the model in a federated environment, but we already offer decorators so that an advancer user can implement its own federated workflow. We design python decorators to handle the following federated learning flows:\n",
    "- initialization: Initialize the model in the server.\n",
    "- deploy model: Deploy the model to the clients.\n",
    "- training: Define the train function.\n",
    "- collect the weights: Collect the weights of the clients params to aggregate them later.\n",
    "- aggregate the weights: Use an aggregation method to aggregte the collected weights.\n",
    "- deploy model: Deploy the model with the updated weights to the clients.\n",
    "- evaluate: Define the evaluate function.\n",
    "\n",
    "In this notebook, we show how to use the defined primitive functions, letting the user the implementation of some key functions:\n",
    "- Define the model to train: It's necessary to tell server and clients which model will be trained.\n",
    "- Aggregator method: In this notebook we will implement FedAvg as the aggregation function.\n",
    "\n",
    "Note that the primitive functions that we offer are basics functions, as we assume how the federated learning training will be. If you want to do a more customizable training loop, please check the notebook \"Federated MNIST PT example with flexible decorators\", as we show there how to implement the primitive functions from scrach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import Dataset, FedDatasetConfig, FedDataDistribution\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "cifar_transforms = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "train_data = datasets.CIFAR10(\n",
    "        root=\".\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=None, # Note that we do not specify transforms here, we provide them later in the training process\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "        root=\".\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=cifar_transforms\n",
    ")\n",
    "\n",
    "\n",
    "config = FedDatasetConfig(seed=0)\n",
    "config.replacement = False\n",
    "config.n_clients = 100\n",
    "\n",
    "flex_dataset = FedDataDistribution.from_config(\n",
    "                        centralized_data=Dataset.from_torchvision_dataset(train_data), \n",
    "                        config=config\n",
    "                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@init_server_model` is a decorator designed to perform the initialization of the server model in a client-server architecture. It has no requirements for specific arguments in the function that uses it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from flex.pool import init_server_model\n",
    "from flex.pool import FlexPool\n",
    "from flex.model import FlexModel\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "def get_model(num_classes=10):\n",
    "    resnet_model = resnet18(weights='DEFAULT')\n",
    "    for p in resnet_model.parameters():\n",
    "        p.requires_grad = False\n",
    "    resnet_model.fc = torch.nn.Linear(resnet_model.fc.in_features, num_classes)\n",
    "    return resnet_model\n",
    "\n",
    "@init_server_model\n",
    "def build_server_model():\n",
    "    server_flex_model = FlexModel()\n",
    "\n",
    "    server_flex_model[\"model\"] = get_model().to(device)\n",
    "    # Required to store this for later stages of the FL training process\n",
    "    server_flex_model[\"criterion\"] = torch.nn.CrossEntropyLoss()\n",
    "    server_flex_model[\"optimizer_func\"] = torch.optim.Adam\n",
    "    server_flex_model[\"optimizer_kwargs\"] = {}\n",
    "\n",
    "    return server_flex_model\n",
    "\n",
    "flex_pool = FlexPool.client_server_architecture(flex_dataset, init_func=build_server_model)\n",
    "\n",
    "clients = flex_pool.clients\n",
    "servers = flex_pool.servers\n",
    "aggregators = flex_pool.aggregators\n",
    "\n",
    "print(f\"Number of nodes in the pool {len(flex_pool)}: {len(servers)} server plus {len(clients)} clients. The server is also an aggregator\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also implement the possibility of select a subsample of the clients in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select clients\n",
    "clients_per_round=2\n",
    "selected_clients_pool = clients.select(clients_per_round)\n",
    "selected_clients = selected_clients_pool.clients\n",
    "\n",
    "print(f\"Server node is indentified by key \\\"{servers.actor_ids[0]}\\\"\")\n",
    "print(f\"Selected {len(selected_clients.actor_ids)} client nodes of a total of {len(clients.actor_ids)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@deploy_server_model` is a decorator designed to copy the model from the server to the clients at each federated learning round. The function that uses it, must have at least one argument, which is the FlexModel object that stores the model at the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import deploy_server_model_pt\n",
    "\n",
    "servers.map(deploy_server_model_pt, selected_clients)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suprisingly, there is no decorator for the training process as it can be imnplemented directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(client_flex_model: FlexModel, client_data: Dataset):\n",
    "    train_dataset = client_data.to_torchvision_dataset(transform=cifar_transforms)\n",
    "    client_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "    model = client_flex_model[\"model\"]\n",
    "    model = model.to(device)\n",
    "    client_flex_model['previous_model'] = deepcopy(model) # Required to use `collect_client_diff_weights_pt` primitive\n",
    "    optimizer = client_flex_model['optimizer_func'](model.parameters(), **client_flex_model[\"optimizer_kwargs\"])\n",
    "    model = model.train()\n",
    "    criterion = client_flex_model[\"criterion\"]\n",
    "    epochs = 5\n",
    "    for _ in tqdm(range(epochs)):\n",
    "        for imgs, labels in client_dataloader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(imgs)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_clients.map(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`collect_client_diff_weights_pt` as it name says, it collects weights from a set of clients. Particularly, it collects the difference between the model before and after training, that is, what the model has learnt in its local training step. Also note that the weights of the model before training are assume to be stored using `previous_model` as key in the FlexModel of a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import collect_client_diff_weights_pt\n",
    "\n",
    "aggregators.map(collect_client_diff_weights_pt, selected_clients)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fed_avg` implements the aggregator Fedeverated Average, which computes the mean of the collected weights in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import fed_avg\n",
    "\n",
    "aggregators.map(fed_avg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set_aggregated_diff_weights_pt` adds the aggregated weights to the weights of the server, it assumes that the aggregated weights have been collected using a similar logic to `collect_client_diff_weights_pt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import set_aggregated_diff_weights_pt\n",
    "\n",
    "aggregators.map(set_aggregated_diff_weights_pt, servers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@evaluate_server_model` is a decorator used to test the server model. The function that uses it must have at least one argument, the FlexModel at the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import evaluate_server_model\n",
    "\n",
    "@evaluate_server_model\n",
    "def evaluate_global_model(server_flex_model: FlexModel, test_data=None):\n",
    "    model = server_flex_model[\"model\"]\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    total_count = 0\n",
    "    model = model.to(device)\n",
    "    criterion=server_flex_model['criterion']\n",
    "    # get test data as a torchvision object\n",
    "    test_dataloader = DataLoader(test_data, batch_size=256, shuffle=True, pin_memory=False)\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_dataloader):\n",
    "            total_count += target.size(0)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            losses.append(criterion(output, target).item())\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            test_acc += pred.eq(target.data.view_as(pred)).long().cpu().sum().item()\n",
    "\n",
    "    test_loss = sum(losses) / len(losses)\n",
    "    test_acc /= total_count\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = servers.map(evaluate_global_model, test_data=test_data)\n",
    "print(metrics[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the federated learning experiment for a few rounds\n",
    "\n",
    "Now, we can summarize the steps provided above and run the federated experiment for multiple rounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar function to clear unused gpu mem in clients\n",
    "def clean_up_models(client_model: FlexModel, _):\n",
    "    import gc\n",
    "    client_model.clear()\n",
    "    gc.collect()\n",
    "\n",
    "def train_n_rounds(n_rounds, clients_per_round=20):  \n",
    "    pool = FlexPool.client_server_architecture(fed_dataset=flex_dataset, init_func=build_server_model)\n",
    "    for i in range(n_rounds):\n",
    "        print(f\"\\nRunning round: {i+1} of {n_rounds}\")\n",
    "        selected_clients_pool = pool.clients.select(clients_per_round)\n",
    "        selected_clients = selected_clients_pool.clients\n",
    "        print(f\"Selected clients for this round: {len(selected_clients)}\")\n",
    "        # Deploy the server model to the selected clients\n",
    "        pool.servers.map(deploy_server_model_pt, selected_clients)\n",
    "        # Each selected client trains her model\n",
    "        selected_clients.map(train)\n",
    "        # The aggregador collects weights from the selected clients and aggregates them\n",
    "        pool.aggregators.map(collect_client_diff_weights_pt, selected_clients)\n",
    "        pool.aggregators.map(fed_avg)\n",
    "        # The aggregator send its aggregated weights to the server\n",
    "        pool.aggregators.map(set_aggregated_diff_weights_pt, pool.servers)\n",
    "        # Optional: evaluate the server model\n",
    "        metrics = pool.servers.map(evaluate_global_model, test_data=test_data)\n",
    "        # Optional: clean-up unused memory\n",
    "        selected_clients.map(clean_up_models)\n",
    "        loss, acc = metrics[0]\n",
    "        print(f\"Server: Test acc: {acc:.4f}, test loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n_rounds(20, clients_per_round=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('snowflakes')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e566fdd1bb8982d94cfadd1b83b7d24c79e08c8cc9caeab62a639b678958baae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
