{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a demonstration of FlexDataset usage\n",
    "\n",
    "First and foremost, we download the dataset we want to federate in this case MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for i in range(9):  \n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.axis('off') \n",
    "    plt.imshow(train_X[i], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encapsulate the chosen dataset in a `FlexDataObject`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import FlexDataObject\n",
    "\n",
    "train_dataset = FlexDataObject(X_data=train_X, y_data=train_y)\n",
    "test_dataset = FlexDataObject(X_data=test_X, y_data=test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a configuration, `FlexDatasetConfig` to federate our dataset, especifically:\n",
    "\n",
    "    - We want to split the dataset between 10 clients.\n",
    "    - Each client will have only one class.\n",
    "    - Each client has only 20% of its assigned class.\n",
    "    - Clients do not share classes between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import FlexDatasetConfig\n",
    "import numpy as np\n",
    "\n",
    "config = FlexDatasetConfig(seed = 0) # We fix a seed to make our federation reproducible\n",
    "config.n_clients = 10 # 10 clients\n",
    "config.replacement = False # ensure that clients do not share any data\n",
    "config.classes_per_client = np.unique(train_y) # assign each client one class\n",
    "config.weights = [0.2] * config.n_clients # each client has only 20% of its assigned class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the generated `FlexDatasetConfig` to a `FlexDataObject`, which encapsulates the centralized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import FlexDataDistribution\n",
    "\n",
    "federated_dataset = FlexDataDistribution.from_config(cdata=train_dataset, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the federated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for client in federated_dataset:\n",
    "    print(f\"Client {client} has class {np.unique(federated_dataset[client].y_data)} and {len(federated_dataset[client])} elements, a sample of them is:\")\n",
    "    #pyplot.figure(figsize = (1,10))\n",
    "    fig, ax = plt.subplots(1, 10) # rows, cols\n",
    "    for i ,(x, y) in enumerate(federated_dataset[client]):\n",
    "        ax[i].axis('off')\n",
    "        ax[i].imshow(x, cmap=plt.get_cmap('gray'))\n",
    "        if i >= 9:\n",
    "            break\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try a more special configuration, we want to federate the dataset such that the number of data per client follows a gaussian distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 500\n",
    "mu, sigma = 100, 1  # mean and standard deviation\n",
    "normal_weights = np.random.default_rng(seed=0).normal(mu, sigma, n_clients)  # sample random numbers\n",
    "normal_weights = np.clip(normal_weights, a_min=0, a_max=np.inf)  # remove negative values\n",
    "normal_weights = normal_weights / sum(normal_weights) # normalize to sum 1\n",
    "\n",
    "plt.hist(normal_weights, bins=15)\n",
    "plt.title('Histogram of normal weights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = FlexDatasetConfig(seed=0, \n",
    "                            n_clients=n_clients,\n",
    "                            replacement=False,\n",
    "                            weights=normal_weights\n",
    "                        )\n",
    "\n",
    "normal_federated_dataset = FlexDataDistribution.from_config(cdata=train_dataset, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot histogram of data per client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasizes_per_client = [len(normal_federated_dataset[client]) for client in normal_federated_dataset]\n",
    "n, bins, patches = plt.hist(datasizes_per_client)\n",
    "plt.ylabel('Data sizes')\n",
    "plt.title('Histogram of data sizes per client')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want, we can normalize the dataset of each client easily, using the `map` function from `FlexDataset`, for example we force each client to keep only pair labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(seed=0)\n",
    "def keep_given_labels(client_dataset: FlexDataObject, selected_labels): # haz aquí otra operación que se te ocurra raruna\n",
    "    client_dataset.X_data = client_dataset.X_data[np.isin(client_dataset.y_data, selected_labels)]\n",
    "    client_dataset.y_data = client_dataset.y_data[np.isin(client_dataset.y_data, selected_labels)]\n",
    "    return client_dataset\n",
    "\n",
    "randomly_transformed_federated_dataset = normal_federated_dataset.map(None,  # Apply to all clients\n",
    "                                                8,  # number of parallel processes \n",
    "                                                keep_given_labels,  # function to apply \n",
    "                                                [0, 2, 4, 6, 8] # argument for function\n",
    "                                                )\n",
    "\n",
    "for client in randomly_transformed_federated_dataset:\n",
    "    print(f\"Client {client} has classes {np.unique(randomly_transformed_federated_dataset[client].y_data)} and {len(randomly_transformed_federated_dataset[client])} elements, a sample of them is:\")\n",
    "    fig, ax = plt.subplots(1, 10) # rows, cols\n",
    "    for i ,(x, y) in enumerate(randomly_transformed_federated_dataset[client]):\n",
    "        ax[i].axis('off')\n",
    "        ax[i].imshow(x, cmap=plt.get_cmap('gray'))\n",
    "        if i >= 9:\n",
    "            break\n",
    "    if client >= 10:\n",
    "        break\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('snowflakes')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f7d2a9c5c2a9c2b510c9da0e3374aeab36a589c02bbbebadbda47bfb5610ebb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
