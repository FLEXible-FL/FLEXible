{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to federate datasets using FLEXible\n",
    "\n",
    "In this notebooks, we show a few of the many ways in which FLEXible can federate a centralized dataset. We will use MNIST and CIFAR10 datasets in this notebooks\n",
    "\n",
    "First, we download it and shot a few samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "ds_train, ds_test = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    batch_size=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use our tools, we need to encapsulate the dataset in a `FlexDataObject`. \n",
    "\n",
    "Note that train_X and train_y are assumed to be NumPy arrays and train_y must be a one dimensional NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import FlexDataObject\n",
    "\n",
    "train_dataset = FlexDataObject.from_tfds_dataset(ds_train)\n",
    "test_dataset = FlexDataObject.from_tfds_dataset(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To federate a centralized dataset, it is required to describe the federation process in a `FlexDatasetConfig` object.\n",
    "\n",
    "A `FlexDatasetConfig` object has the following fields:\n",
    "\n",
    "\n",
    "- **seed**: Optional[int]\n",
    "    Seed used to make the federated dataset generated reproducible with this configuration. Default None.\n",
    "- **n_clients**: Optional[int]\n",
    "    Number of clients among which to split the centralized dataset. If client_names is also given, we consider the number of clients to be the minimun between n_clients and the length of client_names. Default None.\n",
    "- **client_names**: Optional[List[Hashable]]\n",
    "    Names to identifty each client, if not provided clients will be indexed using integers. If n_clients is also given, we consider the number of clients to be the minimun of n_clients and the length of client_names. Default None.\n",
    "- **weights**: Optional[npt.NDArray], A numpy.array which provides the proportion of data to give to each client. Default None.\n",
    "- **replacement**: bool, whether the samping procedure used to split a centralized dataset is with replacement or not. Default True\n",
    "- **classes_per_client**: Optional[Union[int, npt.NDArray, Tuple[int]]], classes to assign to each client, if provided as an int, it is the number classes per client, if provided as a tuple of ints, it establishes a mininum and a maximum of number of classes per client, a random number sampled in such interval decides the number of classes of each client. If provided as a list, it establishes the classes assigned to each client. Default None.\n",
    "- **features_per_client**: Optional[Union[int, npt.NDArray, Tuple[int]]], Features to assign to each client, it share the same interface as classes_per_client.\n",
    "- **indexes_per_client**: Optional[npt.NDArray]\n",
    "    Data indexes to assign to each client, note that this option is incompatible with **classes_per_client**, **features_per_client** options. If replacement and weights are speficied, they are ignored.\n",
    "\n",
    "    The following table shows the compatiblity of each option:\n",
    "\n",
    "    | Options compatibility   | **n_clients** | **client_names** | **weights** | **weights_per_class** | **replacement** | **classes_per_client** | **features_per_client** | **indexes_per_client** |\n",
    "    |-------------------------|---------------|------------------|-------------|-----------------------|-----------------|------------------------|-------------------------|------------------------|\n",
    "    | **n_clients**           | -             | Y                | Y           | Y                     | Y               | Y                      | Y                       | Y                      |\n",
    "    | **client_names**        | Y             | -                | Y           | Y                     | Y               | Y                      | Y                       | Y                      |\n",
    "    | **weights**             | Y             | Y                | -           | N                     | Y               | Y                      | Y                       | N                      |\n",
    "    | **weights_per_class**   | Y             | Y                | N           | -                     | Y               | Y                      | N                       | N                      |\n",
    "    | **replacement**         | Y             | Y                | Y           | Y                     | -               | Y                      | Y                       | N                      |\n",
    "    | **classes_per_client**  | Y             | Y                | Y           | Y                     | Y               | -                      | N                       | N                      |\n",
    "    | **features_per_client** | Y             | Y                | Y           | N                     | Y               | N                      | -                       | N                      |\n",
    "    | **indexes_per_client**  | Y             | Y                | N           | N                     | N               | N                      | N                       | -                      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement the following description:\n",
    "\n",
    "We have 10 federated clients, that do not share any instances, each client with data from a single class and with a 20% of the total data available for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import FlexDatasetConfig\n",
    "import numpy as np\n",
    "\n",
    "config = FlexDatasetConfig(seed = 0) # We fix a seed to make our federation reproducible\n",
    "config.n_clients = 10 # 10 clients\n",
    "config.replacement = False # ensure that clients do not share any data\n",
    "config.classes_per_client = np.unique(train_y) # assign each client one class\n",
    "config.weights = [0.2] * config.n_clients # each client has only 20% of its assigned class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the generated `FlexDatasetConfig` to a `FlexDataObject`, which encapsulates the centralized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import FlexDataDistribution\n",
    "\n",
    "federated_dataset = FlexDataDistribution.from_config(cdata=train_dataset, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the federated data, to confirm that the federated split is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for client in federated_dataset:\n",
    "    print(f\"Node {client} has class {np.unique(federated_dataset[client].y_data)} and {len(federated_dataset[client])} elements, a sample of them is:\")\n",
    "    #pyplot.figure(figsize = (1,10))\n",
    "    fig, ax = plt.subplots(1, 10) # rows, cols\n",
    "    for i ,(x, y) in enumerate(federated_dataset[client]):\n",
    "        ax[i].axis('off')\n",
    "        ax[i].imshow(x, cmap=plt.get_cmap('gray'))\n",
    "        if i >= 9:\n",
    "            break\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federate a dataset using weights to distribute data following a certain distribution\n",
    "\n",
    "We try a more special configuration, we want to federate the dataset such that the number of data per client follows a gaussian distribution, consequently, we need to specify weights from a normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 500\n",
    "mu, sigma = 100, 1  # mean and standard deviation\n",
    "normal_weights = np.random.default_rng(seed=0).normal(mu, sigma, n_clients)  # sample random numbers\n",
    "normal_weights = np.clip(normal_weights, a_min=0, a_max=np.inf)  # remove negative values\n",
    "normal_weights = normal_weights / sum(normal_weights) # normalize to sum 1\n",
    "\n",
    "plt.hist(normal_weights, bins=15)\n",
    "plt.title('Histogram of normal weights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = FlexDatasetConfig(seed=0, \n",
    "                            n_clients=n_clients,\n",
    "                            replacement=False,\n",
    "                            weights=normal_weights\n",
    "                        )\n",
    "\n",
    "normal_federated_dataset = FlexDataDistribution.from_config(cdata=train_dataset, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot histogram of data per client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasizes_per_client = [len(normal_federated_dataset[client]) for client in normal_federated_dataset]\n",
    "n, bins, patches = plt.hist(datasizes_per_client)\n",
    "plt.ylabel('Data sizes')\n",
    "plt.title('Histogram of data sizes per client')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A more complex dataset federation\n",
    "\n",
    "Now, lets federate CIFAR10 that fits the following description from [Personalized Federated Learning using Hypernetworks](https://paperswithcode.com/paper/personalized-federated-learning-using)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we sample two/ten classes for each client for CIFAR10/CIFAR100; Next, for each client i and selected class c, we sample $ \\alpha_{i,c} \\sim U(.4, .6)$, and assign it with $\\frac{\\alpha_{i,c}}{\\sum_j \\alpha_{j,c}}$ of the samples for this class. We repeat the above using 10, 50 and 100 clients. This procedure produces clients with different number of samples and classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) We download the cifar10 dataset using torchivision and create a FlexDataObject with it using ``from_torchvision_dataset``. Note that, it is mandatory to at least provide the ``ToTensor`` transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from flex.data import FlexDataObject\n",
    "\n",
    "cifar10 = datasets.CIFAR10(\n",
    "        root=\".\",\n",
    "        train=True,\n",
    "        download=True\n",
    ")\n",
    "dataset = FlexDataObject.from_torchvision_dataset(cifar10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Create a ``FlexDatasetConfig`` that fits the description given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import FlexDatasetConfig\n",
    "import numpy as np\n",
    "\n",
    "# Sample two/ten classes for each client\n",
    "config = FlexDatasetConfig(seed=0)\n",
    "config.classes_per_client = (2, 10)\n",
    "config.replacement = True # it is not clear whether clients share their data or not\n",
    "config.n_clients = 10\n",
    "num_classes = 10\n",
    "\n",
    "# Assign a sample proportion for each client-class pair\n",
    "alphas = np.random.uniform(0.4, 0.6, [config.n_clients, num_classes])\n",
    "alphas = alphas / np.sum(alphas, axis=0)\n",
    "config.weights_per_class = alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Create the federated dataset by applying the created ``FlexDatasetConfig``to a ``FlexDataObject`` using ``FlexDataDistribution.from_config``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import FlexDataDistribution\n",
    "\n",
    "personalized_cifar_dataset = FlexDataDistribution.from_config(cdata=dataset, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want, we can normalize the dataset of each client easily, using the `map` function from `FlexDataset`, for example we force each client to keep only pair labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(seed=0)\n",
    "def keep_given_labels(client_dataset: FlexDataObject, selected_labels=None):\n",
    "    if not selected_labels:\n",
    "        selected_labels = []\n",
    "    X_data = client_dataset.X_data[np.isin(client_dataset.y_data, selected_labels)]\n",
    "    y_data = client_dataset.y_data[np.isin(client_dataset.y_data, selected_labels)]\n",
    "    return FlexDataObject(X_data=X_data, y_data=y_data)\n",
    "\n",
    "randomly_transformed_federated_dataset = normal_federated_dataset.map(func=keep_given_labels,  # function to apply\n",
    "                                                num_proc=1,\n",
    "                                                selected_labels=[0, 2, 4, 6, 8] # argument for function\n",
    "                                                )\n",
    "\n",
    "for i, client in enumerate(randomly_transformed_federated_dataset):\n",
    "    print(f\"Client {client} has classes {np.unique(randomly_transformed_federated_dataset[client].y_data)} and {len(randomly_transformed_federated_dataset[client])} elements, a sample of them is:\")\n",
    "    fig, ax = plt.subplots(1, 10) # rows, cols\n",
    "    for j ,(x, y) in enumerate(randomly_transformed_federated_dataset[client]):\n",
    "        ax[j].axis('off')\n",
    "        ax[j].imshow(x, cmap=plt.get_cmap('gray'))\n",
    "        if j >= 9:\n",
    "            break\n",
    "    if i >= 10:\n",
    "        break\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END\n",
    "Congratulations, now you know how to federate a dataset using the *FlexDataDistribution* and the *FlexDatasetConfig* classes, so you can setup multiple experimental settings that fit most your hipothesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f7d2a9c5c2a9c2b510c9da0e3374aeab36a589c02bbbebadbda47bfb5610ebb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
