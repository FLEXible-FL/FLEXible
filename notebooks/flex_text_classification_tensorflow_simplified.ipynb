{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLEXible tutorial: Text classification using Tensorflow\n",
    "\n",
    "FLEXible is a library to federate models. We offer the tools to load and federate data or to load federated data, and the tools to create a federated environment. The user can define the model and the *communication primitives* to train the model in a federated environment, but we already offer some simple functions that let the user to build an fast and easy experiment. This primitives can be expressed in the following steps:\n",
    "- initialization: Initialize the model in the server.\n",
    "- deploy model: Deploy the model to the clients.\n",
    "- training: Define the train function.\n",
    "- collect the weights: Collect the weights of the clients params to aggregate them later.\n",
    "- aggregate the weights: Use an aggregation method to aggregte the collected weights.\n",
    "- deploy model: Deploy the model with the updated weights to the clients.\n",
    "- evaluate: Define the evaluate function.\n",
    "\n",
    "In this notebook, we show how to use the defined primitive functions, letting the user the implementation of some key functions:\n",
    "- Define the model to train: It's necessary to tell server and clients which model will be trained.\n",
    "- Aggregator method: In this notebook we will implement FedAvg as the aggregation function.\n",
    "\n",
    "Note that the primitive functions that we offer are basics functions, as we assume how the federated learning training will be. If you want to do a more customizable training loop, please check the notebook flex_text_classifiication_tensorflow_demo, as we show there how to implement the primitive functions from scrach. We will follow this [tutorial](https://www.tensorflow.org/hub/tutorials/tf2_text_classification#build_the_model) from the TensorFlow tutorials for text classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import Dataset\n",
    "\n",
    "flex_data = Dataset.from_tfds_text_dataset(train_data, X_columns='text', label_columns='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import FedDatasetConfig, FedDataDistribution\n",
    "\n",
    "config = FedDatasetConfig(seed=0)\n",
    "config.n_clients = 2\n",
    "config.replacement = False # ensure that clients do not share any data\n",
    "config.client_names = ['client1', 'client2'] # Optional\n",
    "flex_dataset = FedDataDistribution.from_config(cdata=flex_data, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import FedDataDistribution\n",
    "\n",
    "flex_dataset = FedDataDistribution.iid_distribution(flex_data, n_clients=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primitive Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool.primitives import init_server_model_tf\n",
    "from flex.pool.primitives import deploy_server_model_tf\n",
    "from flex.pool.primitives import collect_clients_weights_tf\n",
    "from flex.pool.primitives import train_tf\n",
    "from flex.pool.primitives import set_aggregated_weights_tf\n",
    "from flex.pool.primitives import evaluate_server_model_tf\n",
    "from flex.pool.aggregators import fed_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Defining the model\n",
    "\n",
    "def define_model(**kargs):\n",
    "    model = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "    hub_layer = hub.KerasLayer(model, input_shape=[], dtype=tf.string, trainable=True)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(hub_layer)\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(optimizer='adam',\n",
    "                    loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "                    metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import FlexPool\n",
    "\n",
    "flex_pool = FlexPool.client_server_architecture(fed_dataset=flex_dataset, init_func=init_server_model_tf, model=define_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = flex_pool.clients\n",
    "server = flex_pool.servers\n",
    "print(f\"Server node is indentified by {server.actor_ids}\")\n",
    "print(f\"Client nodes are identified by {clients.actor_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.map(deploy_server_model_tf, clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients.map(train_tf, batch_size=512, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = flex_pool.aggregators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator.map(collect_clients_weights_tf, clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator.map(fed_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator.map(set_aggregated_weights_tf, server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.map(deploy_server_model_tf, clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = Dataset.from_tfds_text_dataset(test_data, X_columns='text', label_columns='label')\n",
    "test_examples, test_labels = test_data.X_data, test_data.y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.map(evaluate_server_model_tf, test_data=test_examples, test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_rounds(n_rounds, batch_size, epochs):  \n",
    "    pool = FlexPool.client_server_architecture(fed_dataset=flex_dataset, init_func=init_server_model_tf, model=define_model())\n",
    "    pool.servers.map(deploy_server_model_tf, pool.clients)\n",
    "    for i in range(n_rounds):\n",
    "        print(f\"\\nRunning round: {i}\\n\")\n",
    "        pool.clients.map(train_tf, batch_size=batch_size, epochs=epochs)\n",
    "        pool.aggregators.map(collect_clients_weights_tf, pool.clients)\n",
    "        pool.aggregators.map(fed_avg)\n",
    "        pool.aggregators.map(set_aggregated_weights_tf, pool.servers)\n",
    "        pool.servers.map(deploy_server_model_tf, pool.clients)\n",
    "        pool.servers.map(evaluate_server_model_tf, test_data=test_examples, test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n_rounds(n_rounds=2, batch_size=512, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c16e99a8b049a3c2333046a7199861cad81dc55b88bad19d31a6edddeb39a963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('flex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
