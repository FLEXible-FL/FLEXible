{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import FlexDataObject, FlexDataset, FlexDatasetConfig, FlexDataDistribution\n",
    "from flex.pool import FlexPool, FlexModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfds.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], \n",
    "                                    batch_size=-1, as_supervised=True)\n",
    "\n",
    "train_examples, train_labels = tfds.as_numpy(train_data)\n",
    "test_examples, test_labels = tfds.as_numpy(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training entries: {len(train_examples)}, test entries: {len(test_examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the FlexDataObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_data = FlexDataObject(X_data=train_examples, y_data=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_data.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = FlexDatasetConfig(seed=0)\n",
    "config.n_clients = 2\n",
    "config.replacement = False # ensure that clients do not share any data\n",
    "config.client_names = ['client1', 'client2']\n",
    "# config.weights = [0.2] * config.n_clients # each client has only 20% of its assigned class\n",
    "config.weights = None\n",
    "flex_dataset = FlexDataDistribution.from_config(cdata=flex_data, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flex_dataset = FlexDataDistribution.iid_distribution(flex_data, n_clients=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the clients and the model to train.\n",
    "\n",
    "Once we've federated the dataset, we have to create the FlexPool. The FlexPool class simulates a real-time scenario for federated learning, so it is in charge of the communications across the actors. The class FlexPool will assign to each actor a role (client, aggregator, server), so they can communicate during the training phase.\n",
    "\n",
    "Please, check the notebook about the actors (TODO: Hacer notebook actores y sus relaciones) to know more about the actors and their relationships in FLEXible.\n",
    "\n",
    "To create a Pool of actors, we need to have a federated dataset, like we've just done, and a model to initialize in the server side, because the server will send the model to the clients so they can train the model. As we have the federated dataset (flex_dataset), we will now create the model.\n",
    "\n",
    "In this case, we will use a model from the tensorflow hub, so we dont have worry about the preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import FlexPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_server_model(flex_model, *args, **kwargs):\n",
    "    print(\"Initializing model server.\")\n",
    "    # model = \"https://tfhub.dev/google/nnlm-en-dim50/2\" # Not working right now, but it's a lower model.\n",
    "    model = \"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2\"\n",
    "    hub_layer = hub.KerasLayer(model, input_shape=[], dtype=tf.string, trainable=True)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(hub_layer)\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(optimizer='adam',\n",
    "                    loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "                    metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])\n",
    "    flex_model['model'] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_pool = FlexPool.client_server_architecture(fed_dataset=flex_dataset, init_func=initialize_server_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_model_to_clients(server_model, clients_model, *args, **kwargs):\n",
    "    print(\"Initializing model at client.\")\n",
    "    for client_id in clients_model:\n",
    "        clients_model[client_id] = deepcopy(server_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = flex_pool.clients\n",
    "server = flex_pool.servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.map(deploy_model_to_clients, clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients._actors.keys() # Check the clients that will participate in the training of the federated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One the model is deployed on the clients, is time to create the training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(client_model, data, *args, **kwargs):\n",
    "    print(\"Training model at client.\")\n",
    "    model = client_model['model']\n",
    "    # client_dataset = tf.data.Dataset.from_tensor_slices((data.X_data, data.y_data))\n",
    "    X_data = data.X_data\n",
    "    y_data = data.y_data\n",
    "    history = model.fit(X_data, y_data, epochs=kwargs['epochs'], batch_size=kwargs['batch_size'],\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients.map(train, batch_size=512, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained the model we have to aggregate the weights. To do so, clients will send the weights to the aggregator, and shed will perform the aggregation told. For the tutorial, we will implement the FevAvg aggregation mechanism.\n",
    "\n",
    "First, we select the aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = flex_pool.aggregators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aggregator._models['server_10865309248']:<keras.engine.sequential.Sequential object at 0x107f65340>}\n",
    "aggregator._models['server_10865309248']['model']:<keras.engine.sequential.Sequential object at 0x107f65340>}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **map** function from *FlexPool* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_weights(client_model, aggregator_model, **kwargs):\n",
    "    # Here the server and the aggregator are the same, so we need to take the ID from the server\n",
    "    # to select the model.\n",
    "    # As the server has a unique ID, we don't know the ID from the server till it's created, so we\n",
    "    # need to take the ID in this way.\n",
    "    if 'weights' not in aggregator_model[\"server\"].keys():\n",
    "        print(\"Aggregating weights.\")\n",
    "        aggregator_model[\"server\"]['weights'] = []\n",
    "\n",
    "    aggregator_model[\"server\"]['weights'].append(client_model['model'].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients.map(collect_weights, aggregator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# TODO: Hace falta función de COLECCIÓN de pesos y otra función de AGREGACIÓN de los pesos. Así queda más claro cual es más claro el proceso de colección y cuál es el procedimiento de agregación. Así en el proceso de colección, podemos filtrar por clientes que tengan un modelo inicializado o no.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_weights(agg_model, *args):\n",
    "    # agg_model[\"weights\"] = np.mean(np.array(agg_model['weights']), axis=0)\n",
    "    agg_model[\"model\"].set_weights(np.mean(np.array(agg_model['weights']), axis=0))\n",
    "    del agg_model[\"weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator.map(aggregate_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the aggregator has the aggregated weights, she should send it to the server. To do so, we will use the *map* function to set the new weights to the server model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_aggregated_weights(aggregator_model, server_model, *args, **kwargs):\n",
    "    print(\"Sending aggregated weights to the server.\")\n",
    "    if 'weights' not in aggregator_model.keys():\n",
    "        raise ValueError('Aggregator should have weights')\n",
    "    for serv in server_model:\n",
    "        server_model[serv]['model'].set_weights(aggregator_model['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator.map(send_aggregated_weights, server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's turn from the server to update the weights from the clients models and then evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_global_model_to_clients(server_model, clients_models, *args, **kwargs):\n",
    "    print(\"Deploying the global model on the clients.\")\n",
    "    aggregated_weights = server_model['model'].get_weights()\n",
    "    for client_model in clients_models:\n",
    "        clients_models[client_model]['model'].set_weights(aggregated_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.map(deploy_global_model_to_clients, clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we can evaluate the model with the test set that we prepared at the begining of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, *args, **kwargs):\n",
    "    model = model['model']\n",
    "    if data is not None:\n",
    "        print(\"Evaluating model at client.\")\n",
    "        results_local = model.evaluate(data.X_data, data.y_data)\n",
    "        print(f\"Results at client on client's data: {results_local}\")\n",
    "    else:\n",
    "        print(\"Evaluating model at server\")\n",
    "    results = model.evaluate(kwargs['test_examples'], kwargs['test_labels'])\n",
    "    print(f\"Results on test data: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.map(evaluate_model, test_examples=test_examples, test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients.map(evaluate_model, test_examples=test_examples, test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together\n",
    "\n",
    "You just have trained a model for 1 round using FLEXible. Now, you could set up all together in a function and iterate for multiple rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_rounds(n_rounds, batch_size, epochs):\n",
    "    pool = FlexPool.client_server_architecture(fed_dataset=flex_dataset, init_func=initialize_server_model)\n",
    "    pool.servers.map(deploy_model_to_clients, pool.clients)\n",
    "    for i in range(n_rounds):\n",
    "        print(f\"\\nRunning round: {i}\\n\")\n",
    "        pool.clients.map(train, batch_size=batch_size, epochs=epochs)\n",
    "        pool.clients.map(evaluate_model, test_examples=test_examples, test_labels=test_labels)\n",
    "        pool.clients.map(collect_weights, pool.aggregators)\n",
    "        pool.aggregators.map(aggregate_weights)\n",
    "        # pool.aggregators.map(send_aggregated_weights, pool.servers) # No hace falta ahora\n",
    "        pool.servers.map(deploy_global_model_to_clients, pool.clients)\n",
    "        pool.servers.map(evaluate_model, test_examples=test_examples, test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n_rounds(n_rounds=4, batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END\n",
    "Congratulations, now you know how to train a model using FLEXible for multiples rounds. Remember that it's important to first deploy/initialize the model on the clients, so you can run the rounds without problem!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c16e99a8b049a3c2333046a7199861cad81dc55b88bad19d31a6edddeb39a963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('flex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
