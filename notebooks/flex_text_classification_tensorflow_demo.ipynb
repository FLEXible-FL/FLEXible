{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLEXible tutorial: Text classification using Tensorflow\n",
    "\n",
    "FLEXible is a library to federate models. We offer the tools to load and federate data or to load federated data, and the tools to create a federated environment. The user must define the model and the *communication primitives* to train the model in a federated environment. This primitives can be expressed in the following steps:\n",
    "- initialization: Initialize the model in the server.\n",
    "- deplot model: Deploy the model to the clients.\n",
    "- training: Define the train function.\n",
    "- collect the weights: Collect the weights of the clients params to aggregate them later.\n",
    "- aggregate the weights: Use an aggregation method to aggregte the collected weights.\n",
    "- deploy model: Deploy the model with the updated weights to the clients.\n",
    "- evaluate: Define the evaluate function.\n",
    "\n",
    "In this notebook, we show how to implement this primitives and how to use FLEXible in orther to federate a model using TensorFlow. In this way, we will train a model using multiple clients, but without sharing any data between clients. We will follow this [tutorial](https://www.tensorflow.org/hub/tutorials/tf2_text_classification#build_the_model) from the TensorFlow tutorials for text classification. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual in every experiment, the first step is to load the dataset we will use. In this case we will use the dataset **imdb_reviews** for a supervised text classification model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the IMBD dataset\n",
    "\n",
    "As used in the tutorial from TensorFlow, we will use the IMBD dataset. This dataset contains reviews about movies, and the *sentiment* associated to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) From centralized data to federated data\n",
    "Firstly and foremost, we need to encapsulare our centralized dataset as numpy arrays in a Dataset, to split it for every federated client.\n",
    "As we are using a centrilized dataset, we have to federate it. To federate the data we need to create a basic data object for FLEXible that is called **Dataset**. To create a  **Dataset** we use the method **from_tfds_dataset** which extracts the features and labels of the dataset and transform them into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import Dataset\n",
    "\n",
    "flex_data = Dataset.from_tfds_text_dataset(train_data, X_columns='text', label_columns='label')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to federate our dataset, we need to specify how we want to split it among clients in a ``FedDatasetConfig`` object. For this case we want to split it evenly between 2 clients, that is, an iid distribution. To apply our config to our centralized dataset, we use ``FedDataDistribution.from_config``. A more complete description of the configuration options of ``FedDatasetConfig`` to federate a dataset can be found in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import FedDatasetConfig, FedDataDistribution\n",
    "\n",
    "config = FedDatasetConfig(seed=0)\n",
    "config.n_clients = 2\n",
    "config.replacement = False # ensure that clients do not share any data\n",
    "config.client_names = ['client1', 'client2'] # Optional\n",
    "flex_dataset = FedDataDistribution.from_config(centralized_data=flex_data, config=config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there is a shortcut, if we want to split the dataset iid between the clients we can directly use ``FedDataDistribution.iid_distribution`` with the number of clients and our centralized data stored in a ``Dataset``. Note that in this case the name of the clients are generated automatically: client number ``i`` gets id: ``f\"client_{i}\"``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import FedDataDistribution\n",
    "\n",
    "flex_dataset = FedDataDistribution.iid_distribution(flex_data, n_clients=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Federating a model with FLEXible\n",
    "\n",
    "Once we've federated the dataset, we have to create the FlexPool. The FlexPool class simulates a real-time scenario for federated learning, so it is in charge of the communications across the actors. The class FlexPool will assign to each actor a role (client, aggregator, server), so they can communicate during the training phase.\n",
    "\n",
    "Please, check the notebook about the actors (TODO: Hacer notebook actores y sus relaciones) to know more about the actors and their relationships in FLEXible.\n",
    "\n",
    "To create a Pool of actors, we need to have a federated dataset, like we've just done, and the model to initialize in the server side, because the server will send the model to the clients so they can train the model. As we have the federated dataset (flex_dataset), we will now create the model.\n",
    "\n",
    "In this case, we will use a model from the tensorflow hub, so we dont have to worry about coding it. We also consider a federated setup commonly know as client server architecture, where a server orchestrates the training of federated clients in every round.\n",
    "\n",
    "In the following, we create a client server architecture and provide a function to initialize the server model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    # model = \"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2\"\n",
    "    model = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "    hub_layer = hub.KerasLayer(model, input_shape=[], dtype=tf.string, trainable=True)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(hub_layer)\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(optimizer='adam',\n",
    "                    loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "                    metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_server_model(server_flex_model, *args):\n",
    "    print(\"Initializing server model.\")\n",
    "    model = define_model()\n",
    "    server_flex_model[\"optimizer\"] = deepcopy(model.optimizer)\n",
    "    server_flex_model[\"loss\"] = deepcopy(model.loss)\n",
    "    server_flex_model[\"metrics\"] = deepcopy(model.compiled_metrics._metrics)\n",
    "    server_flex_model[\"model\"] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import FlexPool\n",
    "\n",
    "flex_pool = FlexPool.client_server_architecture(fed_dataset=flex_dataset, init_func=initialize_server_model)\n",
    "clients = flex_pool.clients\n",
    "server = flex_pool.servers\n",
    "print(f\"Server node is indentified by {server.actor_ids}\")\n",
    "print(f\"Client nodes are identified by {clients.actor_ids}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to create the function that will deploy the model to the clients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_model_to_clients(server_flex_model, clients_model, *args, **kwargs):\n",
    "    from flex.model import FlexModel\n",
    "    for client in clients_model:\n",
    "        weights = server_flex_model[\"model\"].get_weights()\n",
    "        model = tf.keras.models.clone_model(server_flex_model[\"model\"])\n",
    "        model.set_weights(weights)\n",
    "        model.compile(\n",
    "            optimizer=server_flex_model[\"optimizer\"],\n",
    "            loss=server_flex_model[\"loss\"],\n",
    "            metrics=server_flex_model[\"metrics\"],\n",
    "        )\n",
    "        client_flex_model = FlexModel()\n",
    "        client_flex_model['model'] = model\n",
    "        clients_model[client].update(client_flex_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work in an easier way, FlexPool let the use to have organized pools, such as clients, aggregators or servers. This helps to understand how we are connecting the actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = flex_pool.clients\n",
    "server = flex_pool.servers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply all the primitives, such as the deploy step, we will use the **map** function from *FlexPool*. The map function works in the following way: the pool that calls the function map, is the one that will send a message to the destiny pool. If we don't specify it to any pool, no destiny pool, it will \"send\" the message to the same pool that it's calling the map function. This is needed if we want to tell the clients to train/evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.map(deploy_model_to_clients, clients)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is deployed on the clients, is time to create the training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(client_model, client_data, batch_size=256, epochs=1):\n",
    "    print(\"Training model at client.\")\n",
    "    print(client_model)\n",
    "    model = client_model['model']\n",
    "    X_data = client_data.X_data\n",
    "    y_data = client_data.y_data\n",
    "    history = model.fit(X_data, y_data, epochs=epochs, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train the model in the clients side. We will use the *map function* to tell the clients to train the model, and, to do so, we just need to use this function from the clients pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients.map(train, batch_size=512, epochs=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained the model we have to aggregate the weights. To do so, clients will send the weights to the aggregator, and she will perform the aggregation step. For the tutorial, we will implement the FevAvg aggregation mechanism. That is, the aggreation step is split in two steps, 1) for collecting the weights from each client and 2) for averaging them.\n",
    "\n",
    "First, we select the aggregator, which in this case is the same as the server, because in the client server architecture, the server is also an aggregator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = flex_pool.aggregators\n",
    "aggregator.actor_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_weights(aggregator_model, clients_model, **kwargs):\n",
    "    print(\"Collecting weights.\")\n",
    "    if 'weights' not in aggregator_model:\n",
    "        aggregator_model['weights'] = []\n",
    "    for k in clients_model:\n",
    "        client_weights = clients_model[k]['model'].get_weights()\n",
    "        aggregator_model['weights'].append(client_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clients.map(collect_weights, aggregator)\n",
    "aggregator.map(collect_weights, clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_weights(agg_model, *args):\n",
    "    print(\"Aggregating weights\")\n",
    "    averaged_weights = np.mean(np.array(agg_model['weights']), axis=0)\n",
    "    agg_model[\"model\"].set_weights(averaged_weights)\n",
    "    agg_model[\"weights\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator.map(aggregate_weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's turn from the server to update the weights from the clients models and then evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_global_model_to_clients(server_model, clients_models, *args, **kwargs):\n",
    "    print(\"Deploying the global model on the clients.\")\n",
    "    aggregated_weights = server_model['model'].get_weights()\n",
    "    for client_model in clients_models:\n",
    "        clients_models[client_model]['model'].set_weights(aggregated_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.map(deploy_global_model_to_clients, clients)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we can evaluate the model with the test set that we prepared at the begining of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, *args, **kwargs):\n",
    "    model = model['model']\n",
    "    if data is not None:\n",
    "        print(\"Evaluating model at client.\")\n",
    "        results_local = model.evaluate(data.X_data, data.y_data, verbose=0)\n",
    "        print(f\"Results at client on client's data: {results_local}\")\n",
    "    else:\n",
    "        print(\"Evaluating model at server\")\n",
    "    results = model.evaluate(kwargs['test_examples'], kwargs['test_labels'], verbose=0)\n",
    "    print(f\"Results on test data: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_examples, test_labels = test_data\n",
    "test_examples = Dataset.from_tfds_text_dataset(test_data, X_columns='text', label_columns='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.map(evaluate_model, test_examples=test_examples.X_data, test_labels=test_examples.y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients.map(evaluate_model, test_examples=test_examples.X_data, test_labels=test_examples.y_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "\n",
    "You just have trained a model for 1 round using FLEXible. Now, you could set up all together in a function and iterate for multiple rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_rounds(n_rounds, batch_size, epochs):\n",
    "    pool = FlexPool.client_server_architecture(fed_dataset=flex_dataset, init_func=initialize_server_model)\n",
    "    pool.servers.map(deploy_model_to_clients, pool.clients)\n",
    "    for i in range(n_rounds):\n",
    "        print(f\"\\nRunning round: {i}\\n\")\n",
    "        pool.clients.map(train, batch_size=batch_size, epochs=epochs)\n",
    "        pool.clients.map(evaluate_model, test_examples=test_examples.X_data, test_labels=test_examples.y_data)\n",
    "        pool.aggregators.map(collect_weights, pool.clients)\n",
    "        pool.aggregators.map(aggregate_weights)\n",
    "        pool.servers.map(deploy_global_model_to_clients, pool.clients)\n",
    "        pool.servers.map(evaluate_model, test_examples=test_examples.X_data, test_labels=test_examples.y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n_rounds(n_rounds=4, batch_size=512, epochs=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END\n",
    "Congratulations, now you know how to train a model using FLEXible for multiples rounds. Remember that it's important to first deploy/initialize the model on the clients, so you can run the rounds without problem!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f7d2a9c5c2a9c2b510c9da0e3374aeab36a589c02bbbebadbda47bfb5610ebb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
