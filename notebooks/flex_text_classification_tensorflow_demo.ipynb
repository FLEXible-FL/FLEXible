{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLEXible tutorial: Text classification using Tensorflow\n",
    "\n",
    "FLEXible is a library to federate models. We offer the tools to load and federate data or to load federated data, and the tools to create a federated environment. The user must define the model and the *communication primitives* to train the model in a federated environment. This primitives can be expressed in the following steps:\n",
    "- initialization: Initialize the model in the server.\n",
    "- deplot model: Deploy the model to the clients.\n",
    "- training: Define the train function.\n",
    "- collect the weights: Collect the weights of the clients params to aggregate them later.\n",
    "- aggregate the weights: Use an aggregation method to aggregte the collected weights.\n",
    "- deploy model: Deploy the model with the updated weights to the clients.\n",
    "- evaluate: Define the evaluate function.\n",
    "\n",
    "In this notebook, we show how to implement this primitives and how to use FLEXible in orther to federate a model using TensorFlow. In this way, we will train a model using multiple clients, but without sharing any data between clients. We will follow this [tutorial](https://www.tensorflow.org/hub/tutorials/tf2_text_classification#build_the_model) from the TensorFlow tutorials for text classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import FlexDataObject, FlexDataset, FlexDatasetConfig, FlexDataDistribution\n",
    "from flex.pool import FlexPool, FlexModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfds.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the IMBD dataset\n",
    "\n",
    "As used in the tutorial from TensorFlow, we will use the IMBD dataset. This dataset contains reviews about movies, and the *sentiment* associated to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], \n",
    "                                    batch_size=-1, as_supervised=True)\n",
    "\n",
    "train_examples, train_labels = tfds.as_numpy(train_data)\n",
    "test_examples, test_labels = tfds.as_numpy(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training entries: {len(train_examples)}, test entries: {len(test_examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the FlexDataObject\n",
    "\n",
    "As we are using a centrilized dataset, we have to federate it. To federate the data we need to create a basic data object for FLEXible that is called **FlexDataObject**. To create a  **FlexDataObject** we need to have the data as *numpy.arrays*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_data = FlexDataObject(X_data=train_examples, y_data=train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that we created the **FlexDataObject**, we can validate it before federating it, but this step will be done later anyways. The validate function does not return anything, it raises error if there is a problem with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_data.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the FlexDataset\n",
    "\n",
    "Once we hace the FlexDataObject, we can federate the data. We can federate the data in multiple ways, to know more about how to do this, check the [tutorial for FlexDataset](https://github.com/FLEXible-FL/FLEX-framework/blob/main/notebooks/flex_dataset_demo.ipynb). In this example we will use the **FlexDataDistribution** to create an iid_distribution using the function *from_config*, that it's the one recommended for creating multiple ways of federating the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = FlexDatasetConfig(seed=0)\n",
    "config.n_clients = 2\n",
    "config.replacement = False # ensure that clients do not share any data\n",
    "config.client_names = ['client1', 'client2']\n",
    "# config.weights = [0.2] * config.n_clients # each client has only 20% of its assigned class\n",
    "config.weights = None\n",
    "flex_dataset = FlexDataDistribution.from_config(cdata=flex_data, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we could just use the function *iid_distribution* from FlexDataDistribution, that uses the same configuration that we've just used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flex_dataset = FlexDataDistribution.iid_distribution(flex_data, n_clients=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the architecture\n",
    "\n",
    "### Generating the clients and the model to train.\n",
    "\n",
    "Once we've federated the dataset, we have to create the FlexPool. The FlexPool class simulates a real-time scenario for federated learning, so it is in charge of the communications across the actors. The class FlexPool will assign to each actor a role (client, aggregator, server), so they can communicate during the training phase.\n",
    "\n",
    "Please, check the notebook about the actors (TODO: Hacer notebook actores y sus relaciones) to know more about the actors and their relationships in FLEXible.\n",
    "\n",
    "To create a Pool of actors, we need to have a federated dataset, like we've just done, and the model to initialize in the server side, because the server will send the model to the clients so they can train the model. As we have the federated dataset (flex_dataset), we will now create the model.\n",
    "\n",
    "In this case, we will use a model from the tensorflow hub, so we dont have worry about the preprocessing for the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_server_model(flex_model, *args, **kwargs):\n",
    "    print(\"Initializing model server.\")\n",
    "    # model = \"https://tfhub.dev/google/nnlm-en-dim50/2\" # Not working right now, but it's a lower model.\n",
    "    model = \"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2\"\n",
    "    hub_layer = hub.KerasLayer(model, input_shape=[], dtype=tf.string, trainable=True)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(hub_layer)\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(optimizer='adam',\n",
    "                    loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "                    metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])\n",
    "    flex_model['model'] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have compiled the model in the initialize function. This is recommended so we can use the model in the server for further evaluation.\n",
    "\n",
    "In this tutorial we will follow the client-server architecture offered in the FlexDataDistribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_pool = FlexPool.client_server_architecture(fed_dataset=flex_dataset, init_func=initialize_server_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model to clients\n",
    "\n",
    "We have to create the function that will deploy the model to the clients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_model_to_clients(server_model, clients_model, *args, **kwargs):\n",
    "    print(\"Initializing model at client.\")\n",
    "    for client_id in clients_model:\n",
    "        clients_model[client_id] = deepcopy(server_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work in an easier way, FlexPool let the use to have organized pools, such as clients, aggregators or servers. This helps to understand how we are connecting the actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = flex_pool.clients\n",
    "server = flex_pool.servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply all the primitives, such as the deploy step, we will use the **map** function from *FlexPool*. The map function works in the following way: the pool that calls the function map, is the one that will send a message to the destiny pool. If we don't specify it to any pool, no destiny pool, it will \"send\" the message to the same pool that it's calling the map function. This is needed if we want to tell the clients to train/evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.map(deploy_model_to_clients, clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients._actors.keys() # Check the clients that will participate in the training of the federated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the clients models\n",
    "\n",
    "One the model is deployed on the clients, is time to create the training function. As you can see, we use the *fit* function from the TensorFlow model, so we don't need to create it, as we may need in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(client_model, data, *args, **kwargs):\n",
    "    print(\"Training model at client.\")\n",
    "    model = client_model['model']\n",
    "    X_data = data.X_data\n",
    "    y_data = data.y_data\n",
    "    history = model.fit(X_data, y_data, epochs=kwargs['epochs'], batch_size=kwargs['batch_size'],\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train the model in the clients side. We will use the *map function* to tell the clients to train the model, and, to do so, we just need to use this function from the clients pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients.map(train, batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Aggregate the models\n",
    "\n",
    "Now that we have trained the model we have to aggregate the weights. To do so, clients will send the weights to the aggregator, and she will perform the aggregation told. For the tutorial, we will implement the FevAvg aggregation mechanism.\n",
    "\n",
    "First, we select the aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = flex_pool.aggregators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Before applying the FedAvg aggregation method, we have to collect all the parameters (or weights) from the clients models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_weights(client_model, aggregator_model, **kwargs):\n",
    "    # Here the server and the aggregator are the same, so we need to take the ID from the server\n",
    "    # to select the model.\n",
    "    # As the server has a unique ID, we don't know the ID from the server till it's created, so we\n",
    "    # need to take the ID in this way.\n",
    "    if 'weights' not in aggregator_model[\"server\"].keys():\n",
    "        print(\"Aggregating weights.\")\n",
    "        aggregator_model[\"server\"]['weights'] = []\n",
    "\n",
    "    aggregator_model[\"server\"]['weights'].append(client_model['model'].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients.map(collect_weights, aggregator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can aggregate the weights using the FedAvg method. Now that the aggregator has the aggregated weights, she should send it to the server, but, as server and aggregator are the same in our architecture, we will put this step with the fedavg method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fedavg_aggregation(agg_model, *args):\n",
    "    # agg_model[\"weights\"] = np.mean(np.array(agg_model['weights']), axis=0)\n",
    "    agg_model[\"model\"].set_weights(np.mean(np.array(agg_model['weights']), axis=0))\n",
    "    del agg_model[\"weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator.map(fedavg_aggregation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy and evaluate the model.\n",
    "\n",
    "Now it's turn from the server to update the weights from the clients models and then evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_global_model_to_clients(server_model, clients_models, *args, **kwargs):\n",
    "    print(\"Deploying the global model on the clients.\")\n",
    "    aggregated_weights = server_model['model'].get_weights()\n",
    "    for client_model in clients_models:\n",
    "        clients_models[client_model]['model'].set_weights(aggregated_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.map(deploy_global_model_to_clients, clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we can evaluate the model with the test set that we prepared at the begining of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, *args, **kwargs):\n",
    "    model = model['model']\n",
    "    if data is not None:\n",
    "        print(\"Evaluating model at client.\")\n",
    "        results_local = model.evaluate(data.X_data, data.y_data)\n",
    "        print(f\"Results at client on client's data: {results_local}\")\n",
    "    else:\n",
    "        print(\"Evaluating model at server\")\n",
    "    results = model.evaluate(kwargs['test_examples'], kwargs['test_labels'])\n",
    "    print(f\"Results on test data: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.map(evaluate_model, test_examples=test_examples, test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients.map(evaluate_model, test_examples=test_examples, test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "\n",
    "You just have trained a model for 1 round using FLEXible. Now, you could set up all together in a function and iterate for multiple rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_rounds(n_rounds, batch_size, epochs):\n",
    "    pool = FlexPool.client_server_architecture(fed_dataset=flex_dataset, init_func=initialize_server_model)\n",
    "    pool.servers.map(deploy_model_to_clients, pool.clients)\n",
    "    for i in range(n_rounds):\n",
    "        print(f\"\\nRunning round: {i}\\n\")\n",
    "        pool.clients.map(train, batch_size=batch_size, epochs=epochs)\n",
    "        pool.clients.map(evaluate_model, test_examples=test_examples, test_labels=test_labels)\n",
    "        pool.clients.map(collect_weights, pool.aggregators)\n",
    "        pool.aggregators.map(aggregate_weights)\n",
    "        pool.servers.map(deploy_global_model_to_clients, pool.clients)\n",
    "        pool.servers.map(evaluate_model, test_examples=test_examples, test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n_rounds(n_rounds=4, batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END\n",
    "Congratulations, now you know how to train a model using FLEXible for multiples rounds. Remember that it's important to first deploy/initialize the model on the clients, so you can run the rounds without problem!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c16e99a8b049a3c2333046a7199861cad81dc55b88bad19d31a6edddeb39a963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('flex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
