{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLEXible tutorial: MNIST classification using Tensorflow\n",
    "\n",
    "FLEXible is a library to federate models. We offer the tools to load and federate data or to load federated data, and the tools to create a federated environment. The user can define the model and the *communication primitives* to train the model in a federated environment, but we already offer decorators so that an advancer user can implement its own federated workflow. We design python decorators to handle the following federated learning flows:\n",
    "- initialization: Initialize the model in the server.\n",
    "- deploy model: Deploy the model to the clients.\n",
    "- training: Define the train function.\n",
    "- collect the weights: Collect the weights of the clients params to aggregate them later.\n",
    "- aggregate the weights: Use an aggregation method to aggregte the collected weights.\n",
    "- deploy model: Deploy the model with the updated weights to the clients.\n",
    "- evaluate: Define the evaluate function.\n",
    "\n",
    "In this notebook, we show how to use decorators, to implement advanced federated learning concepts.\n",
    "\n",
    "If these tools are not low-level enough, try creating your own decorators or use directly FLEXible at low-level [here](./flex_text_classification_tensorflow_demo.ipynb) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.datasets import load\n",
    "\n",
    "flex_dataset, test_data = load(\"federated_emnist\", return_test=True, split=\"digits\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@init_server_model` is a decorator designed to perform the initialization of the server model in a client-server architecture. It has no requirements for specific arguments in the function that uses it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import init_server_model\n",
    "from flex.pool import FlexPool\n",
    "from flex.model import FlexModel\n",
    "from copy import deepcopy\n",
    "\n",
    "@init_server_model\n",
    "def build_server_model():\n",
    "    server_flex_model = FlexModel()\n",
    "\n",
    "    server_flex_model[\"model\"] = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    server_flex_model[\"model\"].compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # Required to copy this model in later stages of the FL training process\n",
    "    server_flex_model[\"optimizer\"] = deepcopy(server_flex_model[\"model\"].optimizer)\n",
    "    server_flex_model[\"loss\"] = deepcopy(server_flex_model[\"model\"].loss)\n",
    "    server_flex_model[\"metrics\"] = deepcopy(server_flex_model[\"model\"].compiled_metrics._metrics)\n",
    "\n",
    "    return server_flex_model\n",
    "\n",
    "flex_pool = FlexPool.client_server_pool(flex_dataset, init_func=build_server_model)\n",
    "\n",
    "clients = flex_pool.clients\n",
    "servers = flex_pool.servers\n",
    "aggregators = flex_pool.aggregators\n",
    "\n",
    "print(f\"Number of nodes in the pool {len(flex_pool)}: {len(servers)} server plus {len(clients)} clients. The server is also an aggregator\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also implement the possibility of select a subsample of the clients in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select clients\n",
    "clients_per_round=20\n",
    "selected_clients_pool = clients.select(clients_per_round)\n",
    "selected_clients = selected_clients_pool.clients\n",
    "\n",
    "print(f\"Server node is indentified by key \\\"{servers.actor_ids[0]}\\\"\")\n",
    "print(f\"Selected {len(selected_clients.actor_ids)} client nodes of a total of {len(clients.actor_ids)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@deploy_server_model` is a decorator designed to copy the model from the server to the clients at each federated learning round. The function that uses it, must have at least one argument, which is the FlexModel object that stores the model at the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import deploy_server_model\n",
    "\n",
    "@deploy_server_model\n",
    "def copy_server_model_to_clients(server_flex_model: FlexModel):\n",
    "    flex_model = FlexModel()\n",
    "\n",
    "    flex_model[\"model\"] = tf.keras.models.clone_model(server_flex_model[\"model\"])\n",
    "    weights = server_flex_model[\"model\"].get_weights()\n",
    "    flex_model[\"model\"].set_weights(weights)\n",
    "\n",
    "    flex_model[\"model\"].compile(\n",
    "        optimizer=server_flex_model[\"optimizer\"],\n",
    "        loss=server_flex_model[\"loss\"],\n",
    "        metrics=server_flex_model[\"metrics\"],\n",
    "    )\n",
    "    return flex_model\n",
    "\n",
    "\n",
    "servers.map(copy_server_model_to_clients, selected_clients)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suprisingly, there is no decorator for the training process as it can be imnplemented directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import Dataset\n",
    "\n",
    "def train(client_flex_model: FlexModel, client_data: Dataset):\n",
    "    X, y = client_data.to_numpy()\n",
    "    client_flex_model[\"model\"].fit(X, \n",
    "                                    y,\n",
    "                                    epochs=5,\n",
    "                                    batch_size=512,\n",
    "                                    verbose=False)\n",
    "\n",
    "selected_clients.map(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@collect_clients_weights` as it name says, it collects weights from a set of clients, the function that uses it must have at least one argument, the FlexModel from each client, and it is expected to return the weights of her model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import collect_clients_weights\n",
    "\n",
    "@collect_clients_weights\n",
    "def get_clients_weights(client_flex_model: FlexModel):\n",
    "    return client_flex_model[\"model\"].get_weights()\n",
    "\n",
    "aggregators.map(get_clients_weights, selected_clients)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@aggregate_weights` simplifies the process of aggregating and the function using it expects at least one argument, a list that contains the weights collected in the step before using `@collect_clients_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import aggregate_weights\n",
    "import tensorly as tl\n",
    "\n",
    "tl.set_backend('tensorflow')\n",
    "\n",
    "@aggregate_weights\n",
    "def aggregate_with_fedavg(list_of_weights: list):\n",
    "    agg_weights = []\n",
    "    for layer_index in range(len(list_of_weights[0])):\n",
    "        weights_per_layer = tl.stack([weights[layer_index] for weights in list_of_weights])\n",
    "        agg_layer = tl.mean(weights_per_layer, axis=0)\n",
    "        agg_weights.append(agg_layer)\n",
    "    return agg_weights\n",
    "\n",
    "# Aggregate weights\n",
    "aggregators.map(aggregate_with_fedavg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@set_aggregated_weights` is designed as a setter, and it sets the aggregated weights from the aggregator to the server. The function that uses it expects at least two arguments, the FlexModel at the server and the aggregated weights as returned in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import set_aggregated_weights\n",
    "\n",
    "@set_aggregated_weights\n",
    "def set_agreggated_weights_to_server(server_flex_model: FlexModel, aggregated_weights):\n",
    "    server_flex_model[\"model\"].set_weights(aggregated_weights) \n",
    "\n",
    "aggregators.map(set_agreggated_weights_to_server, servers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@evaluate_server_model` is coded to test the server model using external data. The function that uses it must have at least one argument, the FlexModel at the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import evaluate_server_model\n",
    "\n",
    "@evaluate_server_model\n",
    "def evaluate_global_model(server_flex_model: FlexModel, test_data=None):\n",
    "    X, y = test_data.to_numpy()\n",
    "    return server_flex_model[\"model\"].evaluate(X, y, verbose=False)\n",
    "\n",
    "metrics = servers.map(evaluate_global_model, test_data=test_data)\n",
    "print(metrics[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the federated learning experiment for a few rounds\n",
    "\n",
    "Now, we can summarize the steps provided above and run the federated experiment for multiple rounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_rounds(n_rounds, clients_per_round=20):  \n",
    "    pool = FlexPool.client_server_pool(fed_dataset=flex_dataset, init_func=build_server_model)\n",
    "    for i in range(n_rounds):\n",
    "        print(f\"\\nRunning round: {i+1} of {n_rounds}\")\n",
    "        selected_clients_pool = pool.clients.select(clients_per_round)\n",
    "        selected_clients = selected_clients_pool.clients\n",
    "        print(f\"Selected clients for this round: {len(selected_clients)}\")\n",
    "        # Deploy the server model to the selected clients\n",
    "        pool.servers.map(copy_server_model_to_clients, selected_clients)\n",
    "        # Each selected client trains her model\n",
    "        selected_clients.map(train)\n",
    "        # The aggregador collects weights from the selected clients and aggregates them\n",
    "        pool.aggregators.map(get_clients_weights, selected_clients)\n",
    "        pool.aggregators.map(aggregate_with_fedavg)\n",
    "        # The aggregator send its aggregated weights to the server\n",
    "        pool.aggregators.map(set_agreggated_weights_to_server, pool.servers)\n",
    "        metrics = pool.servers.map(evaluate_global_model, test_data=test_data)\n",
    "        loss, acc = metrics[0]\n",
    "        print(f\"Server: Test acc: {acc:.4f}, test loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n_rounds(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('snowflakes')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e566fdd1bb8982d94cfadd1b83b7d24c79e08c8cc9caeab62a639b678958baae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
