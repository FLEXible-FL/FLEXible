{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLEXible tutorial: MNIST classification using Tensorflow\n",
    "\n",
    "FLEXible is a library to federate models. We offer the tools to load and federate data or to load federated data, and the tools to create a federated environment. The user can define the model and the *communication primitives* to train the model in a federated environment, but we already offer some simple functions that let the user to build an fast and easy experiment. This primitives can be expressed in the following steps:\n",
    "- initialization: Initialize the model in the server.\n",
    "- deploy model: Deploy the model to the clients.\n",
    "- training: Define the train function.\n",
    "- collect the weights: Collect the weights of the clients params to aggregate them later.\n",
    "- aggregate the weights: Use an aggregation method to aggregte the collected weights.\n",
    "- deploy model: Deploy the model with the updated weights to the clients.\n",
    "- evaluate: Define the evaluate function.\n",
    "\n",
    "In this notebook, we show how to use the defined primitive functions, letting the user the implementation of some key functions:\n",
    "- Define the model to train: It's necessary to tell server and clients which model will be trained.\n",
    "- Aggregator method: In this notebook we will implement FedAvg as the aggregation function.\n",
    "\n",
    "Note that the primitive functions that we offer are basics functions, as we assume how the federated learning training will be. If you want to do a more customizable training loop, please check the notebook flex_text_classification_tensorflow_demo, as we show there how to implement the primitive functions from scrach. We will follow this [tutorial](https://www.tensorflow.org/tutorials/quickstart/beginner?hl=es-419) from Tensorfllow 2.0 Guide for begginers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.datasets import load\n",
    "\n",
    "flex_dataset, test_data = load(\"federated_emnist\", return_test=True, split=\"digits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import init_server_model\n",
    "from flex.pool import FlexPool\n",
    "from flex.model import FlexModel\n",
    "from copy import deepcopy\n",
    "\n",
    "@init_server_model\n",
    "def build_server_model():\n",
    "    server_flex_model = FlexModel()\n",
    "\n",
    "    server_flex_model[\"model\"] = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    server_flex_model[\"model\"].compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # Required to copy this model in later stages of the FL training process\n",
    "    server_flex_model[\"optimizer\"] = deepcopy(server_flex_model[\"model\"].optimizer)\n",
    "    server_flex_model[\"loss\"] = deepcopy(server_flex_model[\"model\"].loss)\n",
    "    server_flex_model[\"metrics\"] = deepcopy(server_flex_model[\"model\"].compiled_metrics._metrics)\n",
    "\n",
    "    return server_flex_model\n",
    "\n",
    "flex_pool = FlexPool.client_server_architecture(flex_dataset, init_func=build_server_model)\n",
    "\n",
    "clients = flex_pool.clients\n",
    "servers = flex_pool.servers\n",
    "aggregators = flex_pool.aggregators\n",
    "\n",
    "print(f\"Number of nodes in the pool {len(flex_pool)}: {len(servers)} server plus {len(clients)} clients. The server is also an aggregator\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also implement the possibility of select a subsample of the clients in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter clients\n",
    "clients_per_round=20\n",
    "node_dropout = 1-(clients_per_round/len(clients))\n",
    "selected_clients_pool = clients.filter(node_dropout=node_dropout)\n",
    "selected_clients = selected_clients_pool.clients\n",
    "\n",
    "print(f\"Server node is indentified by key \\\"{servers.actor_ids[0]}\\\"\")\n",
    "print(f\"Selected {len(selected_clients.actor_ids)} client nodes of a total of {len(clients.actor_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import deploy_server_model\n",
    "\n",
    "@deploy_server_model\n",
    "def copy_server_model_to_clients(server_flex_model: FlexModel):\n",
    "    flex_model = FlexModel()\n",
    "\n",
    "    flex_model[\"model\"] = tf.keras.models.clone_model(server_flex_model[\"model\"])\n",
    "    weights = server_flex_model[\"model\"].get_weights()\n",
    "    flex_model[\"model\"].set_weights(weights)\n",
    "\n",
    "    flex_model[\"model\"].compile(\n",
    "        optimizer=server_flex_model[\"optimizer\"],\n",
    "        loss=server_flex_model[\"loss\"],\n",
    "        metrics=server_flex_model[\"metrics\"],\n",
    "    )\n",
    "    return flex_model\n",
    "\n",
    "\n",
    "servers.map(copy_server_model_to_clients, selected_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import Dataset\n",
    "\n",
    "def train(client_flex_model: FlexModel, client_data: Dataset):\n",
    "    client_flex_model[\"model\"].fit(client_data.X_data, \n",
    "                                    client_data.y_data,\n",
    "                                    epochs=5,\n",
    "                                    batch_size=512,\n",
    "                                    verbose=False)\n",
    "\n",
    "selected_clients.map(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import collect_clients_weights\n",
    "\n",
    "@collect_clients_weights\n",
    "def get_clients_weights(client_flex_model: FlexModel):\n",
    "    return client_flex_model.model.get_weights()\n",
    "\n",
    "aggregators.map(get_clients_weights, selected_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import aggregate_weights\n",
    "import numpy as np\n",
    "\n",
    "@aggregate_weights\n",
    "def aggregate_with_fedavg(list_of_weights: list):\n",
    "    return np.mean(np.array(list_of_weights, dtype=object), axis=0)\n",
    "\n",
    "# Aggregate weights\n",
    "aggregators.map(aggregate_with_fedavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import set_aggregated_weights\n",
    "\n",
    "@set_aggregated_weights\n",
    "def set_agreggated_weights_to_server(server_flex_model: FlexModel, aggregated_weights):\n",
    "    server_flex_model.model.set_weights(aggregated_weights) \n",
    "\n",
    "aggregators.map(set_agreggated_weights_to_server, servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import evaluate_server_model\n",
    "\n",
    "@evaluate_server_model\n",
    "def evaluate_global_model(server_flex_model: FlexModel, test_data=None):\n",
    "    loss, acc = server_flex_model.model.evaluate(test_data.X_data, test_data.y_data, verbose=False)\n",
    "    print(f\"Test acc {acc:.4f}, test loss {loss:.4f}\")\n",
    "\n",
    "servers.map(evaluate_global_model, test_data=test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the federated learning experiment for a few rounds\n",
    "\n",
    "Now, we can summarize the steps provided above and run the federated experiment for multiple rounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_rounds(n_rounds, clients_per_round=20):  \n",
    "    pool = FlexPool.client_server_architecture(fed_dataset=flex_dataset, init_func=build_server_model)\n",
    "    for i in range(n_rounds):\n",
    "        print(f\"\\nRunning round: {i+1} of {n_rounds+1}\")\n",
    "        node_dropout = 1-(clients_per_round/len(pool.clients))\n",
    "        selected_clients_pool = pool.clients.filter(node_dropout=node_dropout)\n",
    "        selected_clients = selected_clients_pool.clients\n",
    "        print(f\"Selected clients for this round: {len(selected_clients)}\")\n",
    "        # Deploy the server model to the selected clients\n",
    "        pool.servers.map(copy_server_model_to_clients, selected_clients)\n",
    "        # Each selected client trains her model\n",
    "        selected_clients.map(train)\n",
    "        # The aggregador collects weights from the selected clients and aggregates them\n",
    "        pool.aggregators.map(get_clients_weights, selected_clients)\n",
    "        pool.aggregators.map(aggregate_with_fedavg)\n",
    "        # The aggregator send its aggregated weights to the server\n",
    "        pool.aggregators.map(set_agreggated_weights_to_server, pool.servers)\n",
    "        pool.servers.map(evaluate_global_model, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n_rounds(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('snowflakes')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e566fdd1bb8982d94cfadd1b83b7d24c79e08c8cc9caeab62a639b678958baae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
