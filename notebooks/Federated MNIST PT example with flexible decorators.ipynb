{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLEXible tutorial: MNIST classification using Pytorch\n",
    "\n",
    "FLEXible is a library to federate models. We offer the tools to load and federate data or to load federated data, and the tools to create a federated environment. The user can define the model and the *communication primitives* to train the model in a federated environment, but we already offer decorators so that an advancer user can implement its own federated workflow. We design python decorators to handle the following federated learning flows:\n",
    "- initialization: Initialize the model in the server.\n",
    "- deploy model: Deploy the model to the clients.\n",
    "- training: Define the train function.\n",
    "- collect the weights: Collect the weights of the clients params to aggregate them later.\n",
    "- aggregate the weights: Use an aggregation method to aggregte the collected weights.\n",
    "- deploy model: Deploy the model with the updated weights to the clients.\n",
    "- evaluate: Define the evaluate function.\n",
    "\n",
    "In this notebook, we show how to use decorators, to implement advanced federated learning concepts.\n",
    "\n",
    "If these tools are not low-level enough, try creating your own decorators or use directly FLEXible at low-level [here](./flex_text_classification_tensorflow_demo.ipynb) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.datasets import load\n",
    "from torchvision import transforms\n",
    "\n",
    "flex_dataset, test_data = load(\"federated_emnist\", return_test=True, split=\"digits\")\n",
    "\n",
    "mnist_transforms = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@init_server_model` is a decorator designed to perform the initialization of the server model in a client-server architecture. It has no requirements for specific arguments in the function that uses it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from flex.pool import init_server_model\n",
    "from flex.pool import FlexPool\n",
    "from flex.model import FlexModel\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "@init_server_model\n",
    "def build_server_model():\n",
    "    server_flex_model = FlexModel()\n",
    "\n",
    "    server_flex_model[\"model\"] = SimpleNet()\n",
    "    # Required to store this for later stages of the FL training process\n",
    "    server_flex_model[\"criterion\"] = torch.nn.CrossEntropyLoss()\n",
    "    server_flex_model[\"optimizer_func\"] = torch.optim.Adam\n",
    "    server_flex_model[\"optimizer_kwargs\"] = {}\n",
    "    return server_flex_model\n",
    "\n",
    "flex_pool = FlexPool.client_server_architecture(flex_dataset, init_func=build_server_model)\n",
    "\n",
    "clients = flex_pool.clients\n",
    "servers = flex_pool.servers\n",
    "aggregators = flex_pool.aggregators\n",
    "\n",
    "print(f\"Number of nodes in the pool {len(flex_pool)}: {len(servers)} server plus {len(clients)} clients. The server is also an aggregator\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also implement the possibility of select a subsample of the clients in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select clients\n",
    "clients_per_round=20\n",
    "selected_clients_pool = clients.select(clients_per_round)\n",
    "selected_clients = selected_clients_pool.clients\n",
    "\n",
    "print(f\"Server node is indentified by key \\\"{servers.actor_ids[0]}\\\"\")\n",
    "print(f\"Selected {len(selected_clients.actor_ids)} client nodes of a total of {len(clients.actor_ids)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@deploy_server_model` is a decorator designed to copy the model from the server to the clients at each federated learning round. The function that uses it, must have at least one argument, which is the FlexModel object that stores the model at the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import deploy_server_model\n",
    "import copy\n",
    "\n",
    "@deploy_server_model\n",
    "def copy_server_model_to_clients(server_flex_model: FlexModel):\n",
    "    return copy.deepcopy(server_flex_model)\n",
    "\n",
    "\n",
    "servers.map(copy_server_model_to_clients, selected_clients)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suprisingly, there is no decorator for the training process as it can be imnplemented directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train(client_flex_model: FlexModel, client_data: Dataset):\n",
    "    train_dataset = client_data.to_torchvision_dataset(transform=mnist_transforms)\n",
    "    client_dataloader = DataLoader(train_dataset, batch_size=20)\n",
    "    model = client_flex_model[\"model\"]\n",
    "    optimizer = client_flex_model['optimizer_func'](model.parameters(), **client_flex_model[\"optimizer_kwargs\"])\n",
    "    model = model.train()\n",
    "    model = model.to(device)\n",
    "    criterion = client_flex_model[\"criterion\"]\n",
    "    for _ in range(5):\n",
    "        for imgs, labels in client_dataloader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(imgs)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "selected_clients.map(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@collect_clients_weights` as it name says, it collects weights from a set of clients, the function that uses it must have at least one argument, the FlexModel from each client, and it is expected to return the weights of her model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import collect_clients_weights\n",
    "\n",
    "\n",
    "@collect_clients_weights\n",
    "def get_clients_weights(client_flex_model: FlexModel):\n",
    "    weight_dict = client_flex_model[\"model\"].state_dict()\n",
    "    return [weight_dict[name] for name in weight_dict]\n",
    "\n",
    "aggregators.map(get_clients_weights, selected_clients)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@aggregate_weights` simplifies the process of aggregating and the function using it expects at least one argument, a list that contains the weights collected in the step before using `@collect_clients_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import aggregate_weights\n",
    "import tensorly as tl\n",
    "\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "@aggregate_weights\n",
    "def aggregate_with_fedavg(list_of_weights: list):\n",
    "    agg_weights = []\n",
    "    for layer_index in range(len(list_of_weights[0])):\n",
    "        weights_per_layer = [weights[layer_index] for weights in list_of_weights]\n",
    "        weights_per_layer = tl.stack(weights_per_layer)\n",
    "        agg_layer = tl.mean(weights_per_layer, axis=0)\n",
    "        agg_weights.append(agg_layer)\n",
    "    return agg_weights\n",
    "\n",
    "# Aggregate weights\n",
    "aggregators.map(aggregate_with_fedavg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@set_aggregated_weights` is designed as a setter, and it sets the aggregated weights from the aggregator to the server. The function that uses it expects at least two arguments, the FlexModel at the server and the aggregated weights as returned in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import set_aggregated_weights\n",
    "\n",
    "@set_aggregated_weights\n",
    "def set_agreggated_weights_to_server(server_flex_model: FlexModel, aggregated_weights):\n",
    "    with torch.no_grad():\n",
    "        weight_dict = server_flex_model[\"model\"].state_dict()\n",
    "        for layer_key, new in zip(\n",
    "            weight_dict, aggregated_weights\n",
    "        ):\n",
    "            weight_dict[layer_key].copy_(new)\n",
    "\n",
    "aggregators.map(set_agreggated_weights_to_server, servers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@evaluate_server_model` is coded to test the server model using external data. The function that uses it must have at least one argument, the FlexModel at the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import evaluate_server_model\n",
    "\n",
    "@evaluate_server_model\n",
    "def evaluate_global_model(server_flex_model: FlexModel, test_data=None):\n",
    "    model = server_flex_model[\"model\"]\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    total_count = 0\n",
    "    model = model.to(device)\n",
    "    criterion=server_flex_model['criterion']\n",
    "    # get test data as a torchvision object\n",
    "    test_dataset = test_data.to_torchvision_dataset(transform=mnist_transforms)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=True, pin_memory=False)\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            total_count += target.size(0)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            losses.append(criterion(output, target).item())\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            test_acc += pred.eq(target.data.view_as(pred)).long().cpu().sum().item()\n",
    "\n",
    "    test_loss = sum(losses)/len(losses)\n",
    "    test_acc /= total_count\n",
    "    return test_loss, test_acc\n",
    "\n",
    "metrics = servers.map(evaluate_global_model, test_data=test_data)\n",
    "print(metrics[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the federated learning experiment for a few rounds\n",
    "\n",
    "Now, we can summarize the steps provided above and run the federated experiment for multiple rounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_rounds(n_rounds, clients_per_round=20):  \n",
    "    pool = FlexPool.client_server_architecture(fed_dataset=flex_dataset, init_func=build_server_model)\n",
    "    for i in range(n_rounds):\n",
    "        print(f\"\\nRunning round: {i+1} of {n_rounds}\")\n",
    "        selected_clients_pool = pool.clients.select(clients_per_round)\n",
    "        selected_clients = selected_clients_pool.clients\n",
    "        print(f\"Selected clients for this round: {len(selected_clients)}\")\n",
    "        # Deploy the server model to the selected clients\n",
    "        pool.servers.map(copy_server_model_to_clients, selected_clients)\n",
    "        # Each selected client trains her model\n",
    "        selected_clients.map(train)\n",
    "        # The aggregador collects weights from the selected clients and aggregates them\n",
    "        pool.aggregators.map(get_clients_weights, selected_clients)\n",
    "        pool.aggregators.map(aggregate_with_fedavg)\n",
    "        # The aggregator send its aggregated weights to the server\n",
    "        pool.aggregators.map(set_agreggated_weights_to_server, pool.servers)\n",
    "        metrics = pool.servers.map(evaluate_global_model, test_data=test_data)\n",
    "        loss, acc = metrics[0]\n",
    "        print(f\"Server: Test acc: {acc:.4f}, test loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n_rounds(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('snowflakes')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e566fdd1bb8982d94cfadd1b83b7d24c79e08c8cc9caeab62a639b678958baae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
