{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLEXible tutorial: MNIST classification using Tensorflow\n",
    "\n",
    "FLEXible is a library to federate models. We offer the tools to load and federate data or to load federated data, and the tools to create a federated environment. The user can define the model and the *communication primitives* to train the model in a federated environment, but we already offer some simple functions that let the user to build an fast and easy experiment. This primitives can be expressed in the following steps:\n",
    "- initialization: Initialize the model in the server.\n",
    "- deploy model: Deploy the model to the clients.\n",
    "- training: Define the train function.\n",
    "- collect the weights: Collect the weights of the clients params to aggregate them later.\n",
    "- aggregate the weights: Use an aggregation method to aggregte the collected weights.\n",
    "- deploy model: Deploy the model with the updated weights to the clients.\n",
    "- evaluate: Define the evaluate function.\n",
    "\n",
    "In this notebook, we show how to use the defined primitive functions, letting the user the implementation of some key functions:\n",
    "- Define the model to train: It's necessary to tell server and clients which model will be trained.\n",
    "- Aggregator method: In this notebook we will implement FedAvg as the aggregation function.\n",
    "\n",
    "Note that the primitive functions that we offer are basics functions, as we assume how the federated learning training will be. If you want to do a more customizable training loop, please check the notebook flex_text_classifiication_tensorflow_demo, as we show there how to implement the primitive functions from scrach. We will follow this [tutorial](https://www.tensorflow.org/tutorials/quickstart/beginner?hl=es-419) from Tensorfllow 2.0 Guide for begginers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import Dataset\n",
    "from flex.datasets import load\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "flex_dataset, test_data = load(\"federated_emnist\", return_test=True, split=\"digits\")\n",
    "\n",
    "def remove_writer_from_y_data(client_dataset: Dataset):\n",
    "    new_x_data = client_dataset.X_data\n",
    "    new_y_data = np.asarray([y[0] for y in client_dataset.y_data])  # each label is a tuple (mnist_label, writer), so we remove the writer\n",
    "    return Dataset(new_x_data, new_y_data)\n",
    "\n",
    "flex_dataset = flex_dataset.map(remove_writer_from_y_data)\n",
    "test_data = remove_writer_from_y_data(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primitive Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool.primitives import init_server_model_tf\n",
    "from flex.pool.primitives import deploy_server_model_tf\n",
    "from flex.pool.primitives import collect_clients_weights_tf\n",
    "from flex.pool.primitives import train_tf\n",
    "from flex.pool.primitives import set_aggregated_weights_tf\n",
    "from flex.pool.primitives import evaluate_server_model_tf\n",
    "from flex.pool.aggregators import fed_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Defining the model\n",
    "\n",
    "def define_model(**kargs):\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import FlexPool\n",
    "\n",
    "flex_pool = FlexPool.client_server_architecture(fed_dataset=flex_dataset, init_func=init_server_model_tf, model=define_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter clients\n",
    "filtered_pool = flex_pool.filter(node_dropout=0.99)\n",
    "\n",
    "clients = filtered_pool.clients\n",
    "total_clients = flex_pool.clients\n",
    "server = flex_pool.servers\n",
    "print(f\"Server node is indentified by {server.actor_ids}\")\n",
    "\n",
    "print(f\"LENGTH: Client nodes are identified by {len(clients.actor_ids)}\")\n",
    "print(f\"LENGTH: Client nodes are identified by {len(total_clients.actor_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.map(deploy_server_model_tf, clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients.map(train_tf, batch_size=512, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = flex_pool.aggregators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator.map(collect_clients_weights_tf, clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator.map(fed_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator.map(set_aggregated_weights_tf, server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.map(deploy_server_model_tf, clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.data import Dataset\n",
    "\n",
    "test_examples, test_labels = test_data.X_data, test_data.y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.map(evaluate_server_model_tf, test_data=test_examples, test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_rounds(n_rounds, batch_size, epochs):  \n",
    "    pool = FlexPool.client_server_architecture(fed_dataset=flex_dataset, init_func=init_server_model_tf, model=define_model())\n",
    "    pool.servers.map(deploy_server_model_tf, pool.clients)\n",
    "    for i in range(n_rounds):\n",
    "        print(f\"\\nRunning round: {i}\\n\")\n",
    "        pool.clients.map(train_tf, batch_size=batch_size, epochs=epochs)\n",
    "        pool.aggregators.map(collect_clients_weights_tf, pool.clients)\n",
    "        pool.aggregators.map(fed_avg)\n",
    "        pool.aggregators.map(set_aggregated_weights_tf, pool.servers)\n",
    "        pool.servers.map(deploy_server_model_tf, pool.clients)\n",
    "        pool.servers.map(evaluate_server_model_tf, test_data=test_examples, test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n_rounds(n_rounds=2, batch_size=512, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
